==============
General
==============

Shared Responsibility Model
  - what does user control vs AWS
    - On Premises -> Datacenter Hosted -> Infrastructure as a Service -> Platform as a Service -> Software as a Service
  - User is responsible for security ON the cloud
    - client-side stuff, operating system, firewall, file system, data, encryption, etc.
  - AWS is responsible for security OF the cloud
    - AWS software, infrastructure, storage, etc.

Availability
  - High Availability
    - Ensure performance for higher than normal period
      - period can be big or bigger
      - If something fails, it can quickly be replaced
      - replacement might make users log in again, for instance, but that's OK.

  - Fault Tolerance
    - ensure system keeps working through failure
      - Like if above example didn't make user log in again. Redundancy is a good tool here.

  - Disaster Recovery
    - What to do if HA/FT fail
    - pre-planned and documented processes
    - backups stored elsewhere from main storage

Public vs Private Services
  - Refers to networking and where you can access from
  - Private services can't be accessed from outside VPC (not connected to VPC)
  - Private Zone is like a home network, things inside can talk to stuff that things outside can't
    - VPCs are inside Private Zone
  - "AWS Public" zone is between public internet and VPC
    - Not inside public internet, but connected to it.
    - S3 for instance is here
    - You use public internet to get to AWS Public zone, which routes your requests internally
  - VPN can connect private-to-private network directly to private zone (edge case, eg on premises)
  - Internet Gateway can allow private zone stuff to access internet, or go directly to AWS Public zone for s3 queries, etc.
    - EC2 instance can have a public IP for instance.
      - Projects EC2 into Amazon Public Zone

Global Infrastructure
  - Regions -> Edge Locations
    - Edge locations are good for netflix, for instance. Better performance.
  - Regions give
    - Isolated fault domain
    - Geopolitical / legal separation
      - Different laws might apply
    - control; you might expand infra into a different region for better performance
  - Availability Zones
    - isolated hardware
    - architecture can distribute between them for region resiliance


==============
VPC
==============

- Virtual network
- Created within one region and one account
- by default, private and isolated from public AWS zone and other VPCs
- VPC CIDR defines range of IPs in use
- Subdivisions of VPC (Subnets) are each located in 1 AZ


Default VPC is a pre-configured thing that we don't use
  - only one per region per account
  - CIDR is 172.31.0.0/16
  - One subnet per AZ in region, /20 size
    - plenty of spare room
  - Internet gateway, Security Group, NACL created
  - Anything placed in default subnet gets a public IP. Different from Custom VPC
  - can be deleted / recreated

Design considerations
  - are there networks we have to avoid
    - other vpcs, cloud, on-premises, partners/vendors
  - what size range
    - vpcs can be between /28 (16 ips) and /16 (65536 ips)
  - how many ranges
    - how many subnets
      - how many AZs?
        - three per region seems good, plus a buffer for a total of 4 subnets due to AZs
      - how many tiers? a common pattern is
        - public web tier
        - private with gateway application tier
        - private with no gateway database tier
        - let's add a spare
      - So, 16 subnets per account. if starting with /16 vpc, this would be /20 each subnet.
        - starting with /18 would make /22 subnets
      - how many accounts?
        - Prod, dev, general, spare
      - we need 48 ip ranges
  - the class lost me here re: the A4L example. it started talking about having 4 vpcs per region/account but also all AZs and all Tiers as subnets in 1 vpc
    - not sure where the 4vpcs come from. just being big?
  - don't forget we need a vpc per region
  - try to predict the future (?)
    - is there more to that than "leave spare room"

Custom VPC
  - isolated; nothing in or out without explicit permissions
  - hybrid networking: on-premises + cloud
  - 2 hardware tenancy setups
    - Default
      - shared hardware
      - can choose per-resource to have dedicated hardware
    - Dedicated
      - can no longer choose shared hardware
      - more expensive
  - everything gets private IP, public ips are given when we need them
  - one primary IP4 CIDR /16 block
    - up to 5 (more with support) secondary cidr blocks
      - these are if you run out of space, essentially
  - one optional IP6 /56 CIDR block
    - can't choose block, can supply ones you already own
  - DNS
    - provided by Route53
    - dns ip is base ip + 2
    - VPC-level options
      - EnableDnsHostnames
        - because ips can be dynamic and this will resolve correctly
          - why did I not know this while working on reply-guy?
      - EnableDnsSupport
        - enables or disables DNS resolution

Subnets
  - AZ Resilient, inside 1 AZ
  - ip4 cidr is subset of vpc cider
    - optional ip6 /64 range, 1/256th of the VPC ip6 range
  - subnets in a vpc can't overlap
  - by default, can freely communicate between subnets within a vpc
  - reserved addresses
    - first is vpc itself, network address
    - first + 1 is vpc router
    - first + 2 is dns address, helps use hostnames internally and externally
    - first + 3 is reserved for future use
    - last is Network Broadcast address which talks to every host
      - broadcasting is not actually useable in VPC
  - for every vpc there is a DHCP option set
    - DHCP assigns IP addresses
    - can't edit options, can create new option set instead
    - applies to all subnets in vpc
    - options
      - Do we give resources a public ipv4 address by default?
      - Do we give resources a ipv6 address?

Routing
  - 

      



==============
Cloudformation
==============

Does cloud stuff based on config file
  - In YAML (maybe json?), Description field, if used, must directly follow AWSTemplateFormatVersion
  - Metadata field controls UI among other things
  - Parameters add options for user to select when using CFN UI
  - Mappings makes lookup tables
  - Conditions are a thing
  - Outputs are like, what is the resulting ec2 id and stuff, probably goes in a log somewhere

CFN templates create stacks (a template can start many stacks). Stacks make stuff (ec2 instance, etc.)
  - Deleting stack deletes the stuff
  - Template -> logical resource (stack) -> physical resource (stuff)


==============
Route53
==============

Globally resillient, no region

 
Register Domains
  - Has relationships with major domain registries, which manage top level domains as vested by IANA
  - Registration process:
    - First, check with top level organization if domain is available
    - Create zonefile (database for domain with DNS info)
    - Allocate nameservers (4 per zone) - this is a "hosted zone"
      - Tell top level org about these. They add nameserver records that communicate with hosted zone

Host Zones (managed nameservers) and general DNS flow
  - Can be public or private (linked to VPC)
  - stores records
    - nameserver records
      - "amazon.com" in the .com zone points to servers in the amazon.com zone
      - root zone similarly points to .com zone
    - A & AAAA records
      - in amazon.com zone, the host/name of www (subdomains may or may not be hosts) might map to an ip address.
        - CNAMES can point multiple domains to same host/name (NOT DIRECTLY TO IP)
      - A maps to ipv4, AAAA maps to ipv6
        - usually create both for client compatibility
    - Cname
      - see above
    - MX
      - routes emails to servers
        - A record for "mail"
        - MX record for "mail"
        - another MX record for "mail.stuff."
          - dot on right means it's fully qualified and can point outside zone
            - maybe a different mail service that the zone owner likes better
        - mail server sees to: stuff@gmail.com
          - queries gmail.com for MX records
          - resolves priority (lower # is higher prio) 
          - gets hostname, then has to query for IP
    - TXT
      - arbitrary, can be used to prove to google for instance that you own the domain you say you do
        - other patterns exist, but the key is only the owner can add stuff and that helps
  - TTL
    - Walking the above tree takes time, but you get an authoritative answer for what IP to hit
    - This answer can come with a TTL, which allows resolver server (like 8.8.8.8, for instance) to cache answer (now non-authoritative)
   


=========================
EBS - Elastic Block Store
=========================

- Storage attached to ec2 instance 

GP (General Purpose)
  - speed based on size

GP2: credit bucket architecture
initial credits
can burst, refills at base 100 credits/sec + 3 per gb

GP3: base 3000 iops, can pay for more
  - simpler, max 4x faster, cheaper
  - extra speed added manually



IO (Provisioned IOPS)
  - speed independent of size
  - for low latency + consistency



HDD
  - slow, cheap

st1: Throughput Optimized
  - max 500MB/s
    - 40MB/s/tb base
    - 250MB/s/tb burst
  - bucket system like gp2, base + burse
  - for big data

sc1: cold
  - cheapest, for archives
  - max 250MB/s
    - 12MB/s/tb base
    - 80MB/s/tb burst


=========================
EBS Snapshots
=========================

- Moves from EBS' availability zone resilience to S3 (region resilient)
- Incremental (think diffs)
- can be copied to other regions, can restore volumes
- restores are lazy, performance can suffer soon after restore
- FSR Fast Snapshot Restore costs extra, avoids laziness and you can have 50 per region
  - can just force the reads manually instead
- Billed GB/month
- snapshots only billed USED data on volume


=========================
IAM
=========================

Identities are IAM users, IAM groups (sort of), and IAM roles 

Identity policies are attached to Identities

ARN
  - unique identifers (unique within account)
    - most things unique across account + region
    - some things like IAM users unique within account
    - some things like s3 unique globally
  - slightly varied format
    - arn:aws:service:region:account-id:resource-id
    - arn:aws:service:region:account-id:resource-type/resource-id
    - arn:aws:service:region:account-id:resource-type:resource-id
  - "aws" is always the same for commercial aws (not government, etc)

Policy document (config) has statements with
  - action
    - "servicename:action", also can be specific action or list of them, including wildcards
  - resource
    - same as above, but instead of servicename:action, arn is used
  - effect 
    - allow or deny, conflicts are resolved in priority order
      - deny
      - allow
      - default is deny
  - optional Sid

Identity can have multiple policies
  - Someone can have 2 or more policies attached to them, and be in a group with another policy attached
    - same rules apply. If the group is explicitly denied, the user can't access it even if their personal roles specifically allow it.

Inline policies are not best practice
  - have to change it everywhere it's applied
  - can be good for exceptions when one identity needs special treatment
Managed Policy instead
  - create policy object and assign it to many things

IAM users are an identity used for long term AWS access (people, apps, service accounts)
  - if you can point to a named thing that needs access, it probably wants to have a user
  - Principal is the thing trying to authenticate as a user

5000 Users per account
  - for big companies, roles & identity federation can work
User can be in 10 groups

IAM Groups are containers for users
  - you cannot log into a group
  - like users, groups can have inline or managed policy attached
    - managed policies can be AWS-managed (built-in) or customer managed (custom)
  - no limit to how many users in group
  - no default "all users" group
  - no groups nested in groups
  - 300 groups limit
  - resource policy can't grant access to a group
    - they aren't true identities

IAM roles
  - temporary, a hat you put on for a short job
    - temp credentials are given via STS
  - roles have Trust policy and Permissions policy
    - Trust policy specifies who can assume role
      - can be users, services, can be used anonymously
    - Permissions policy specifies what permissions the role has
  - use cases
    - give aws services like lambda permission to stop ec2 instances or whatever
    - emergency role for break glass scenarios
    - existing identity provider (web identity federation)
      - no aws credentials stored in application
    - > 5000 staff
    - cross-account, give other account permissions
  - service-linked role
    - predefined role linked to an aws service
    - can't delete unless service is no longer using it
    - PassRole action permissions let you pass service-linked roles to other services
      - When an AWS service needs to assume a role, a user must have iam:PassRole permissions to pass that role to the service.


=========================
Organizations
=========================

Groups accounts
  - subgroups under Organizational Root are Organizational Units
    - can be nested

The account that makes the Organization is the management/master/payer account
  - can't be restricted
  - can invite accounts to join org
    - those accounts go from being standard accounts to member accounts
      - consolidated billing: Billing passes through to payer account
        - consolidates volume discounts

can create accounts directly in organizations
best practice is that only one account is logged into (maybe master acct, maybe not)
  - other accounts have roles this account can log into (role switching)
SCPs manage permissions for member accounts
  - can be attached to accounts, OUs, or Org root
  - inherit down
  - can't affect management account
  - can indirectly restrict account root user (not usually possible)
  - don't grant permissions, only defines what COULD be allowed
    - default SCP is FullAWSAccess
      - doesn't actually grant permissions, identity policies still needed


=========================
Cloudwatch
=========================

Public zone service
Regional
log = info + timestamp
many aws services are integrated by default
log stream is a sequence of log events from the same source
log group is a container of log streams
  - settings are set here, like retention settings
  - can generate metrics from log data
    - looks for patterns, increments metric, can trigger alarms


=========================
Cloudwatch
=========================


Has UI, CLI, and API interfaces (i imagine most services do)

Metrics
  - a metric is a time-ordered set of data points
    - Dimensions are used to identify
      - EC2 InstanceId could be a dimension, but so could InstanceType. Depends what they think someone might want to look at
      - can't add dimensions to native metrics, only custom
  - some things are automatically gathered (ec2 cpu usage)
  - some external things need Cloudwatch agent to add metrics

Logs
  - same same but different

Events
  - can perform actions based on metrics
  - can perform actions at a certain time
  - can for instance send an email based on an alarm

Namespace
  - custom for external data
  - "AWS/EC2" (for instance) for native things

logs API calls and aws activities as cloudtrail events
  - can be action taken by user, role, or service
  - stored 90 days by default, free
  - can be 1 of 3 kinds of events
    - management events
      - creating/terminating instances, create vpc
      - enabled by default
    - data events
      - objects added to s3, lambda invoked
      - not enabled by default because it's a lot!
    - insight events

can create trails for customization
  - logs events in a region
  - can be configured to log global service events
    - enabled by default
    - consolidated into us-east-1 specifically
  - can be all-region, which is basically just one in each region operating as one logical trail
    - so changes to configuration will apply to all regions and new regions are added automatically
  - can be stored in S3 as json
  - can be stored in Cloudwatch Logs as well
    - search through, use metric filters
  - you can make an organization trail using the org management account
    - for consolidation

There is a delay!
  - within 15min usually


=========================
AWS Control Tower
=========================

Orchestrates organizations and other services to set up a multi-account environment

Landing Zone
  - has home region
  - uses organizations, AWS Config, Cloudformation, etc. to work
  - like organization, has management account
  - sets up SSO, centralized logging
  - creates 2 OUs
    - Foundational "security"
      - creates 2 accounts
        - Audit
        - Log archive
          - users who need all logging info
    - Custom "sandbox"

Guard Rails
  - 3 types: Mandatory, Strongly Recommended, Elective
  - Function in 2 ways
    - Preventative: uses SCP to stop things from happening
    - Detective: uses AWS Config to detect when things happen
      - clear, in violation, or not enabled

Account Factory automates and standardizes new account creation
  - guard rails can be auto applied
  - account admin given to named user
  - configure network like ip ranges
  - accounds can be deleted
  - can be integrated into a business' SDLC


=========================
S3
=========================

Security
  - Private by default
  - Bucket policies
    - type of resource policy
    - how you give access to something to identities outside your account, since you can't attach identity policies to them
    - can grant access to anonymous principals
    - statements look like Identity policy's, with additional Principal field
    - can block by conditions like matching IP, uses MFA, more
  - Access Control List
    - Legacy, not recommended
    - Subresource (like object is to bucket)
      - can be attached to object or bucket
    - inflexible
      - no conditions
  - Block Public Access
    - apply only to anonymous principal
    - can block
      - everything
      - things granted by new ACLs
      - things granted by all ACLs
      - things granted by new resource/access point policies
      - things granted by all resource/access point policies

Static Website Hosting
  - need to point to an index and error page
  - if you want to use custom domain, bucket name needs to match
  - good for offloading image serving, etc. from ec2

Object versioning
  - controlled at bucket level
  - can be enabled and suspended, but cannot be disabled
    - suspending and deleting existing versions manually is kinda like disabling
  - does what you expect, stores multiple versions
  - version number is called "id", compared to the object "key" (like a filename)
  - can request specific version by ID
  - when we "delete" an object and don't give an ID, the current version becomes a delete marker (hides all versions)
    - can delete the delete marker
    - specifying id does actually delete the version
  - MFA Delete
    - must use MFA to delete versions and to suspend versioning (or enable it)

Perforance Optimization
  - Single PUT upload can be unreliable
    - needs to restart upload if connection drops
    - limited to 5GB, which is already ridiculous
  - Multipart Upload
    - minimum size is 100MB
    - 10000 max parts between 5mb and 5gb (except last remainder part)
    - each part can be restarted
    - faster
  - Transfer Acceleration
    - helps problem of public internet and ISPs tossing our upload all over the place before it gets to S3 instance we want
    - gets to closest AWS edge location via public internet, then tunneled via AWS-controlled network straight where it goes
    - off by default
    - bucket name must be dns compatible, with no periods
    - more benefits as distance increases between uploader and destination bucket

Encryption
  - Buckets are not encrypted. Objects are.
    - each object can use different encryption settings
  - encryption-in-transit is used, can't see inside the tunnel
    - some exceptions
  - client-side encryption-at-rest
    - just upload some encrypted data lol
    - no longer supported by itself, everything is encrypted
      - of course, they can't prevent you from doing both
  - server-side encryption-at-rest
    - unencrypted objects inside encrypted tunnel are encrypted by S3 when they get there
    - 3 types
      - SSE with S3-Manged keys (SSE-S3)
        - default
        - you provide plaintext object and S3 makes a key
        - no options, invisible
        - per-object key is further encrypted by master S3 key, plaintext discarded and cyphertext per-object key saved
        - can't stop S3 full admin from seeing all data
          - might be illegal re: medical records, etc.
          - no Role Separation
        - uses AES-256 encryption
      - SSE with keys in KMS (SSE-KMS)
        - uses KMS key that you can configure
        - this takes the place of the master S3 key above
        - have logging and auditing against key using Cloudtrail, etc.
      - SSE with Customer-provided keys (SSE-C)
        - you provide key and object
        - s3 encrypts object and hashes key + object, attaches hash to object
        - s3 discards key
        - managing key creation is good for high regulatory environments
  - Bucket Keys
    - without bucket keys, encryption process for SSE-KMS requires a lot of calls to KMS, multiple per upload
      - There is throttling with KMS keys, too, so it isn't just an efficiency thing
    - KMS key is used to create a time-limited bucket key, which can be used to generate DEKs per 
      - this works because the bucket key is re-deriveable from the KMS key.
      - Only the KMS key is needed to decrypt
      - Kinda seems the same as caching the KMS key in memory, but transparently with best practices
      - Fewer KMS Cloudtrail logs, and they will have the bucket ARN, not object ARN
  - Replicating plain text objects to a bucket with bucket key or default encryption can change the "ETAG"

Storage Classes
  - S3 Standard
    - Duplicated across at least 3 AZs
    - "11 9's" of durability, 1 lost object every 10,000 years
    - replication is checked for accuracy with CRCs
    - if an object is durably stored like this, HTTP/1.1 200 OK status.
    - pay for storage gb/m; transfer OUT per gb, not in; and price per 1000 requests
    - can be made public, no minimum duration or size
    - first byte latency in ms, fast 
    - balanced and good for frequently accessed data that is important and non-replaceable
  - S3 Standard-IA (Infrequent Access)
    - cheaper to store, but has retrieval fee
      - retrieval fee (basically an access fee) but not transfer fee could apply to data that never leaves AWS (accessing a log for instance)
    - minimum duration billed: 30 days
    - minimum billed object size: 128KB
    - good for few accesses of important, irreplaceable data
      - once per month?
  - S3 OneZone-IA (Infrequent Access)
    - Like above without replication
    - cheaper still
    - for data that can be replaced
    - Basically never fails but you wouldn't bet your business on it
  - S3 Glacier-Instant
    - Like Standard-IA, but cheaper to store, more expensive to access, and 90 day minimum
    - good for data accessed once per quarter
  - S3 Glacier-Flexible
    - Formerly S3 Glacier
    - 1/6 the cost of S3 standard
    - not immediately available
    - can't be made public, including static website hosting
    - retrieval process needs to be done in advance of accessing
      - temporarily puts them in S3 Standard-IA until accessed
      - 3 types of retrieval
        - Expedited: 1-5 min
        - Standard: 3-5 hours
        - Bulk: 5-12 hours
        - Faster = more expensive (duh)
    - 40kb min size
    - 90 day min duration
  - S3 Glacier-Deep Archive
    - cheaper yet
    - like above but 180 day min
    - Standard retrieval: 12hr
    - Bulk retrieval: 48hr
    - good for regulatory archives, stuff that shouldn't ever have to be retrieved but needs to be kept
    - good as secondary backup
  - S3 Intelligent Tiering
    - 5 levels kinda map to above
      - Frequent
      - Infrequent
      - Archive Instant
      - Archive 
      - Deep Archive 
    - monitors usage and moves from tier to tier intelligently
    - Archive and Deep Archive require application changes and has same "dethawing" process
      - They are optional
    - Tiers higher than Archive do not incur retrieval fees
    - monitoring and automation fee instead
    - good for long lived data with unpredictable usage spikes

Lifecycle Configuration
  - applied to bucket or group of objects (prefix, tags)
  - rules consist of actions
    - can't trigger based on access patterns
    - 2 types
      - Transition actions change storage class (say, move to IA after 30 days)
        - can transition from more expensive -> less  
          - Intelligent Tiering is between IA and OneZone IA
          - weird exception: can't transition from OneZone IA to Glacier Instant Retrieval
        - remember that transitioning small objects could incur cost bc min sizes
        - Transitioning from Standard requires object to be in Standard for 30 days
          - can still transition manually tho
          - weirdness: doing so to Standard-IA or OneZone-IA starts another 30 day timer until you can move down to glaciers
            - BUT ONLY IF YOU WANT TO DO IT WITH ONE RULE??
      - Expiration actions delete after a while

Replication
  - cross-region or same region replication
  - can replicate to bucket in other account
      - destination bucket needs to have bucket policy to trust source account
  - Replication configuration
    - destination bucket
    - IAM Role to use
    - all objects or a group of them (prefix, tags)
    - optionally change storage class
    - ownership (what account owns object)
      - might want to make this the destination account if cross-account replication
    - RTC (replication time control)
      - Speeds up to < 15min vs "best effort"
      - costs extra
  - not retroactive by default
    - can configure "batch replication" to replicate existing objects
  - must enable versioning on source and destination
  - one directional by default
  - can handle encrypted objects, though extra config needed for SSE-KMS.
  - source bucket needs permissions for objects
  - won't replicate changes to lifecycle config, tags by default, other system events
  - can't replicate Glacier Flexible or Glacier deep archive
  - no delete markers by default
  - use cases for same Region 
    - resilience where regulations means data stays in one region
    - could use to aggregate multiple buckets' logs
    - sync some prod and test data
  - use cases for cross Region 
    - global resilience
    - reduce latency

Presigned URL
  - to create, someone with permissions supplies credentials, bucket + object, expiration time
  - allows unauthenticated request for object upload/download
  - when given the URL, unauthenticated user operates on object as the person who generated it
    - permissions are NOT baked in at generation
  - this is how you would have a website with videos only for logged in users
    - web server asks s3 for presigned url to send to logged in user
    - otherwise, videos would have to be public
  - you can generate a useless presigned url by not having access to the specified object
    - permissions can change shortly after to make it useful
  - don't generate using an IAM role (temp role credentials could expire at unpredictable times and break the URL)

S3 Select and Glacier Select
  - use sql-like statements to retrieve parts of objects
    - data stored as JSON, CSV, others
  - because client side filtering isn't cost-effective for big objects

S3 Events
  - older feature, eventbridge might be better
  - Can be delivered to SNS topics, SQS queues, lambdas
  - can trigger on put, post, copy, CompleteMultiPartUpload, deletes, restores, some replication stuff
  - Event Notification Config
  - lambda, etc. needs resource policy to allow S3 principal to interact
    - weirdly no way to edit lambda resource policy via UI?

S3 Access logs
  - log accesses of source bucket to some other target bucket
  - best effort, few hours
  - happens through "log delivery group"
    - built-in service principal
  - target bucket needs ACL to accept from LDG
    - bucket policies can't specify built-in AWS service principals, go figure
  - newline-delimited records with space-delimited attributes
  - logging configuration sets prefix for logfile
  - need to manually delete

S3 Object Lock
  - Existing buckets need support to turn on
  - versioning required; individual versions are what is locked
  - means no overwrites or deletes of that version
  - 2 ways it manages retention, both or either (or none) can be active
    - Retention Period
      - specify days and years to retain.
      - 2 modes
        - Compliance Mode
          - retention period / lock itself cannot be reduced, even by account root user!
        - Governance Mode
          - similar, but you can get special permissions to remove the lock
    - Legal Hold
      - Not time-based, just on or off
      - For when a version is critical
  - Bucket default settings are possible in addition to individual vesion settings

- S3 Access Points
  - Intermediary between principal and bucket
    - simplifies access management
      - instead of monolithic bucket policies, different groups with different permissions can access same bucket
  - can be set to be accessed only directly from within vpc
    - needs vpc endpointin vpc
  - for some reason CLI command is important to remember: "aws s3control create-access-point"
  - access points have unique DNS addresses
  - common pattern is for bucket policy to allow everything from a given access point, then use access point policies to actually manage permissions


=========================
Key Management System
=========================

Regional and Public
  - multiregion keys are supported, off by default
Create, store, and manage keys for cryptography
  - both symmetric and asymmetric
Perform encrypt, decrypt, etc.
Keys never leave the service
Compliant with FIPS 140-2 level 2
KMS Keys
  - formerly CMKs
  - contain id, creation date, key (resource) policy, description, and state
  - container for actual key data
    - can be generated or imported
    - up to 4kb of key data
  - granular permissions: decrypt, create, encrypt, etc. are separate
  - Support rotation, on by default
    - rotation mostly invisible
    - old versions are kept so you can decrypt pre-rotation encrypted files
  - can alias, so that you can swap keys
Data Encryption Keys
  - DEKs use KMS Keys
    - linked to KMS key
  - work on > 4KB
  - KMS doesn't operate on DEKs, it gives it to you to work with
    - plaintext
    - cyphertext
      - can be used with linked KMS key to get plaintext DEK
    - workflow:
      - encrypt data using DEK plaintext
      - discard plaintext DEK
      - store encrypted DEK with data
Key Policy
  - every key has one
  - unlike other services, keys don't automatically trust account they're in
    - usually, you explicitly grant access to the account then use IAM to grant usage rights
    - in higher security situations, you might skip IAM and grant permissions directly in key policy
  - there's another thing called grants













































